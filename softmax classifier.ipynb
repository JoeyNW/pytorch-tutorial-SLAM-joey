{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb157aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T03:41:15.947124Z",
     "start_time": "2021-08-04T03:40:10.739149Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/MNIST\\raw\\train-images-idx3-ubyte.gz to data/mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz to data/mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz to data/mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%D:\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data/mnist/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# class\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# prepare data\n",
    "batch_size = 64\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))]) # 转换为网络需要的格式以及标准化，均值，方差\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data/mnist/', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = datasets.MNIST(root='data/mnist/', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6692ce1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T03:44:27.977111Z",
     "start_time": "2021-08-04T03:44:26.330538Z"
    }
   },
   "outputs": [],
   "source": [
    "# design model using class\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(784, 512)\n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 128)\n",
    "        self.l4 = torch.nn.Linear(128, 64)\n",
    "        self.l5 = torch.nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # -1表示自动计算784的个数，也就是有多少个样本\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x) # 最后一层不做激活，因为要用crossentropy，自带了softmax\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "991815ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:12:08.865328Z",
     "start_time": "2021-08-04T07:12:08.854385Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.5)\n",
    "\n",
    "# train cycle\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()\n",
    "        # 获得预测结果\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 300 == 299:\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch+1, batch_idx+1, running_loss/300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs.data, dim=1) #dim=1，从列的方向找寻最大值，返回的第一个参数是值，第二个值是下标\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"accracy on test_set: %d %%\" % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "057f1802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:15:14.895851Z",
     "start_time": "2021-08-04T07:12:44.356671Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 2.248\n",
      "[1,   600] loss: 1.043\n",
      "[1,   900] loss: 0.457\n",
      "accracy on test_set: 87 %\n",
      "[2,   300] loss: 0.327\n",
      "[2,   600] loss: 0.272\n",
      "[2,   900] loss: 0.243\n",
      "accracy on test_set: 94 %\n",
      "[3,   300] loss: 0.190\n",
      "[3,   600] loss: 0.173\n",
      "[3,   900] loss: 0.151\n",
      "accracy on test_set: 95 %\n",
      "[4,   300] loss: 0.132\n",
      "[4,   600] loss: 0.117\n",
      "[4,   900] loss: 0.121\n",
      "accracy on test_set: 96 %\n",
      "[5,   300] loss: 0.099\n",
      "[5,   600] loss: 0.097\n",
      "[5,   900] loss: 0.089\n",
      "accracy on test_set: 96 %\n",
      "[6,   300] loss: 0.074\n",
      "[6,   600] loss: 0.080\n",
      "[6,   900] loss: 0.073\n",
      "accracy on test_set: 97 %\n",
      "[7,   300] loss: 0.063\n",
      "[7,   600] loss: 0.061\n",
      "[7,   900] loss: 0.061\n",
      "accracy on test_set: 97 %\n",
      "[8,   300] loss: 0.049\n",
      "[8,   600] loss: 0.047\n",
      "[8,   900] loss: 0.055\n",
      "accracy on test_set: 97 %\n",
      "[9,   300] loss: 0.038\n",
      "[9,   600] loss: 0.044\n",
      "[9,   900] loss: 0.044\n",
      "accracy on test_set: 97 %\n",
      "[10,   300] loss: 0.031\n",
      "[10,   600] loss: 0.035\n",
      "[10,   900] loss: 0.034\n",
      "accracy on test_set: 97 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8828d9",
   "metadata": {},
   "source": [
    "# practice-otto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5872ccb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:28:35.866091Z",
     "start_time": "2021-08-05T07:28:35.337901Z"
    }
   },
   "outputs": [],
   "source": [
    "# otto\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data_train = pd.read_csv(\"data/otto/train.csv\")\n",
    "# data_test = pd.read_csv(\"data/otto/test.csv\")\n",
    "\n",
    "# 将类别标签转换为数字\n",
    "def label2id(lables):\n",
    "    target_id = []\n",
    "    target_labels = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']\n",
    "    for label in lables:\n",
    "        target_id.append(target_labels.index(label))\n",
    "    return target_id\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# prepare dataset\n",
    "class OttoDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        data = pd.read_csv(filepath)\n",
    "        lables = data['target']\n",
    "        self.len = data.shape[0]\n",
    "        \n",
    "        self.x_data = torch.from_numpy(np.array(data)[:,1:-1].astype(float)) #必须转换成float\n",
    "        self.y_data = label2id(lables)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "data_train = OttoDataset(\"data/otto/train.csv\")\n",
    "# data_test = OttoDataset(\"data/otto/test.csv\")\n",
    "train_loader = DataLoader(dataset=data_train, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c27b3ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:42:58.866133Z",
     "start_time": "2021-08-05T07:42:58.851140Z"
    }
   },
   "outputs": [],
   "source": [
    "# design model using class\n",
    "\n",
    "class ottoNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ottoNet, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(93, 64)\n",
    "        self.l2 = torch.nn.Linear(64, 32)\n",
    "        self.l3 = torch.nn.Linear(32, 16)\n",
    "        self.l4 = torch.nn.Linear(16, 9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        return self.l4(x) # 最后一层不做激活，因为要用crossentropy，自带了softmax\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = F.relu(self.l1(x))\n",
    "            x = F.relu(self.l2(x))\n",
    "            x = F.relu(self.l3(x))\n",
    "            x = self.l4(x)\n",
    "            _, predicted = torch.max(x, dim=1)\n",
    "            # 将预测的类别转为one-hot表示，方便保存为预测文件。\n",
    "#             y = pd.get_dummies(predicted)\n",
    "            return predicted\n",
    "            \n",
    "model = ottoNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75f4aa0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:34:05.761095Z",
     "start_time": "2021-08-05T07:34:05.744852Z"
    }
   },
   "outputs": [],
   "source": [
    "# contruct loss and optimzer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "def train(epoch):\n",
    "    running_loss=0.0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        inputs, target = data\n",
    "        inputs = inputs.float()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, batch_idx+1, running_loss/300))\n",
    "            running_loss = 0.0       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce5e24a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:36:14.870145Z",
     "start_time": "2021-08-05T07:34:07.859858Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 1.552\n",
      "[1,   600] loss: 0.884\n",
      "[1,   900] loss: 0.777\n",
      "[2,   300] loss: 0.739\n",
      "[2,   600] loss: 0.703\n",
      "[2,   900] loss: 0.705\n",
      "[3,   300] loss: 0.673\n",
      "[3,   600] loss: 0.676\n",
      "[3,   900] loss: 0.648\n",
      "[4,   300] loss: 0.643\n",
      "[4,   600] loss: 0.629\n",
      "[4,   900] loss: 0.627\n",
      "[5,   300] loss: 0.603\n",
      "[5,   600] loss: 0.618\n",
      "[5,   900] loss: 0.613\n",
      "[6,   300] loss: 0.599\n",
      "[6,   600] loss: 0.598\n",
      "[6,   900] loss: 0.586\n",
      "[7,   300] loss: 0.581\n",
      "[7,   600] loss: 0.574\n",
      "[7,   900] loss: 0.578\n",
      "[8,   300] loss: 0.570\n",
      "[8,   600] loss: 0.571\n",
      "[8,   900] loss: 0.558\n",
      "[9,   300] loss: 0.562\n",
      "[9,   600] loss: 0.555\n",
      "[9,   900] loss: 0.551\n",
      "[10,   300] loss: 0.545\n",
      "[10,   600] loss: 0.561\n",
      "[10,   900] loss: 0.537\n",
      "[11,   300] loss: 0.545\n",
      "[11,   600] loss: 0.531\n",
      "[11,   900] loss: 0.547\n",
      "[12,   300] loss: 0.527\n",
      "[12,   600] loss: 0.547\n",
      "[12,   900] loss: 0.532\n",
      "[13,   300] loss: 0.521\n",
      "[13,   600] loss: 0.531\n",
      "[13,   900] loss: 0.532\n",
      "[14,   300] loss: 0.510\n",
      "[14,   600] loss: 0.529\n",
      "[14,   900] loss: 0.529\n",
      "[15,   300] loss: 0.506\n",
      "[15,   600] loss: 0.523\n",
      "[15,   900] loss: 0.519\n",
      "[16,   300] loss: 0.517\n",
      "[16,   600] loss: 0.506\n",
      "[16,   900] loss: 0.511\n",
      "[17,   300] loss: 0.501\n",
      "[17,   600] loss: 0.506\n",
      "[17,   900] loss: 0.510\n",
      "[18,   300] loss: 0.497\n",
      "[18,   600] loss: 0.505\n",
      "[18,   900] loss: 0.504\n",
      "[19,   300] loss: 0.496\n",
      "[19,   600] loss: 0.502\n",
      "[19,   900] loss: 0.501\n",
      "[20,   300] loss: 0.488\n",
      "[20,   600] loss: 0.492\n",
      "[20,   900] loss: 0.500\n",
      "[21,   300] loss: 0.488\n",
      "[21,   600] loss: 0.487\n",
      "[21,   900] loss: 0.494\n",
      "[22,   300] loss: 0.472\n",
      "[22,   600] loss: 0.499\n",
      "[22,   900] loss: 0.492\n",
      "[23,   300] loss: 0.483\n",
      "[23,   600] loss: 0.487\n",
      "[23,   900] loss: 0.487\n",
      "[24,   300] loss: 0.475\n",
      "[24,   600] loss: 0.475\n",
      "[24,   900] loss: 0.491\n",
      "[25,   300] loss: 0.477\n",
      "[25,   600] loss: 0.481\n",
      "[25,   900] loss: 0.487\n",
      "[26,   300] loss: 0.468\n",
      "[26,   600] loss: 0.477\n",
      "[26,   900] loss: 0.478\n",
      "[27,   300] loss: 0.472\n",
      "[27,   600] loss: 0.479\n",
      "[27,   900] loss: 0.469\n",
      "[28,   300] loss: 0.470\n",
      "[28,   600] loss: 0.465\n",
      "[28,   900] loss: 0.473\n",
      "[29,   300] loss: 0.462\n",
      "[29,   600] loss: 0.469\n",
      "[29,   900] loss: 0.475\n",
      "[30,   300] loss: 0.464\n",
      "[30,   600] loss: 0.465\n",
      "[30,   900] loss: 0.466\n",
      "[31,   300] loss: 0.462\n",
      "[31,   600] loss: 0.463\n",
      "[31,   900] loss: 0.467\n",
      "[32,   300] loss: 0.461\n",
      "[32,   600] loss: 0.457\n",
      "[32,   900] loss: 0.470\n",
      "[33,   300] loss: 0.456\n",
      "[33,   600] loss: 0.463\n",
      "[33,   900] loss: 0.461\n",
      "[34,   300] loss: 0.457\n",
      "[34,   600] loss: 0.450\n",
      "[34,   900] loss: 0.468\n",
      "[35,   300] loss: 0.455\n",
      "[35,   600] loss: 0.450\n",
      "[35,   900] loss: 0.465\n",
      "[36,   300] loss: 0.449\n",
      "[36,   600] loss: 0.457\n",
      "[36,   900] loss: 0.459\n",
      "[37,   300] loss: 0.450\n",
      "[37,   600] loss: 0.450\n",
      "[37,   900] loss: 0.457\n",
      "[38,   300] loss: 0.446\n",
      "[38,   600] loss: 0.457\n",
      "[38,   900] loss: 0.448\n",
      "[39,   300] loss: 0.444\n",
      "[39,   600] loss: 0.452\n",
      "[39,   900] loss: 0.450\n",
      "[40,   300] loss: 0.450\n",
      "[40,   600] loss: 0.447\n",
      "[40,   900] loss: 0.444\n",
      "[41,   300] loss: 0.437\n",
      "[41,   600] loss: 0.449\n",
      "[41,   900] loss: 0.454\n",
      "[42,   300] loss: 0.440\n",
      "[42,   600] loss: 0.442\n",
      "[42,   900] loss: 0.448\n",
      "[43,   300] loss: 0.436\n",
      "[43,   600] loss: 0.440\n",
      "[43,   900] loss: 0.450\n",
      "[44,   300] loss: 0.434\n",
      "[44,   600] loss: 0.452\n",
      "[44,   900] loss: 0.441\n",
      "[45,   300] loss: 0.442\n",
      "[45,   600] loss: 0.432\n",
      "[45,   900] loss: 0.448\n",
      "[46,   300] loss: 0.442\n",
      "[46,   600] loss: 0.438\n",
      "[46,   900] loss: 0.438\n",
      "[47,   300] loss: 0.424\n",
      "[47,   600] loss: 0.434\n",
      "[47,   900] loss: 0.454\n",
      "[48,   300] loss: 0.436\n",
      "[48,   600] loss: 0.434\n",
      "[48,   900] loss: 0.445\n",
      "[49,   300] loss: 0.432\n",
      "[49,   600] loss: 0.441\n",
      "[49,   900] loss: 0.435\n",
      "[50,   300] loss: 0.437\n",
      "[50,   600] loss: 0.429\n",
      "[50,   900] loss: 0.434\n",
      "[51,   300] loss: 0.431\n",
      "[51,   600] loss: 0.434\n",
      "[51,   900] loss: 0.436\n",
      "[52,   300] loss: 0.428\n",
      "[52,   600] loss: 0.427\n",
      "[52,   900] loss: 0.439\n",
      "[53,   300] loss: 0.423\n",
      "[53,   600] loss: 0.435\n",
      "[53,   900] loss: 0.435\n",
      "[54,   300] loss: 0.427\n",
      "[54,   600] loss: 0.436\n",
      "[54,   900] loss: 0.428\n",
      "[55,   300] loss: 0.420\n",
      "[55,   600] loss: 0.436\n",
      "[55,   900] loss: 0.428\n",
      "[56,   300] loss: 0.414\n",
      "[56,   600] loss: 0.433\n",
      "[56,   900] loss: 0.429\n",
      "[57,   300] loss: 0.417\n",
      "[57,   600] loss: 0.425\n",
      "[57,   900] loss: 0.433\n",
      "[58,   300] loss: 0.421\n",
      "[58,   600] loss: 0.427\n",
      "[58,   900] loss: 0.428\n",
      "[59,   300] loss: 0.419\n",
      "[59,   600] loss: 0.419\n",
      "[59,   900] loss: 0.433\n",
      "[60,   300] loss: 0.419\n",
      "[60,   600] loss: 0.425\n",
      "[60,   900] loss: 0.423\n",
      "[61,   300] loss: 0.425\n",
      "[61,   600] loss: 0.420\n",
      "[61,   900] loss: 0.418\n",
      "[62,   300] loss: 0.416\n",
      "[62,   600] loss: 0.417\n",
      "[62,   900] loss: 0.427\n",
      "[63,   300] loss: 0.410\n",
      "[63,   600] loss: 0.424\n",
      "[63,   900] loss: 0.419\n",
      "[64,   300] loss: 0.411\n",
      "[64,   600] loss: 0.420\n",
      "[64,   900] loss: 0.423\n",
      "[65,   300] loss: 0.410\n",
      "[65,   600] loss: 0.421\n",
      "[65,   900] loss: 0.426\n",
      "[66,   300] loss: 0.413\n",
      "[66,   600] loss: 0.411\n",
      "[66,   900] loss: 0.423\n",
      "[67,   300] loss: 0.410\n",
      "[67,   600] loss: 0.413\n",
      "[67,   900] loss: 0.423\n",
      "[68,   300] loss: 0.407\n",
      "[68,   600] loss: 0.414\n",
      "[68,   900] loss: 0.427\n",
      "[69,   300] loss: 0.414\n",
      "[69,   600] loss: 0.415\n",
      "[69,   900] loss: 0.421\n",
      "[70,   300] loss: 0.398\n",
      "[70,   600] loss: 0.422\n",
      "[70,   900] loss: 0.419\n",
      "[71,   300] loss: 0.407\n",
      "[71,   600] loss: 0.411\n",
      "[71,   900] loss: 0.416\n",
      "[72,   300] loss: 0.407\n",
      "[72,   600] loss: 0.407\n",
      "[72,   900] loss: 0.416\n",
      "[73,   300] loss: 0.409\n",
      "[73,   600] loss: 0.408\n",
      "[73,   900] loss: 0.417\n",
      "[74,   300] loss: 0.401\n",
      "[74,   600] loss: 0.404\n",
      "[74,   900] loss: 0.418\n",
      "[75,   300] loss: 0.405\n",
      "[75,   600] loss: 0.410\n",
      "[75,   900] loss: 0.405\n",
      "[76,   300] loss: 0.404\n",
      "[76,   600] loss: 0.409\n",
      "[76,   900] loss: 0.409\n",
      "[77,   300] loss: 0.409\n",
      "[77,   600] loss: 0.401\n",
      "[77,   900] loss: 0.411\n",
      "[78,   300] loss: 0.408\n",
      "[78,   600] loss: 0.402\n",
      "[78,   900] loss: 0.406\n",
      "[79,   300] loss: 0.400\n",
      "[79,   600] loss: 0.405\n",
      "[79,   900] loss: 0.413\n",
      "[80,   300] loss: 0.397\n",
      "[80,   600] loss: 0.416\n",
      "[80,   900] loss: 0.397\n",
      "[81,   300] loss: 0.395\n",
      "[81,   600] loss: 0.409\n",
      "[81,   900] loss: 0.402\n",
      "[82,   300] loss: 0.400\n",
      "[82,   600] loss: 0.399\n",
      "[82,   900] loss: 0.412\n",
      "[83,   300] loss: 0.395\n",
      "[83,   600] loss: 0.408\n",
      "[83,   900] loss: 0.400\n",
      "[84,   300] loss: 0.399\n",
      "[84,   600] loss: 0.400\n",
      "[84,   900] loss: 0.405\n",
      "[85,   300] loss: 0.390\n",
      "[85,   600] loss: 0.397\n",
      "[85,   900] loss: 0.414\n",
      "[86,   300] loss: 0.395\n",
      "[86,   600] loss: 0.407\n",
      "[86,   900] loss: 0.400\n",
      "[87,   300] loss: 0.401\n",
      "[87,   600] loss: 0.400\n",
      "[87,   900] loss: 0.399\n",
      "[88,   300] loss: 0.386\n",
      "[88,   600] loss: 0.403\n",
      "[88,   900] loss: 0.404\n",
      "[89,   300] loss: 0.389\n",
      "[89,   600] loss: 0.400\n",
      "[89,   900] loss: 0.405\n",
      "[90,   300] loss: 0.396\n",
      "[90,   600] loss: 0.401\n",
      "[90,   900] loss: 0.397\n",
      "[91,   300] loss: 0.390\n",
      "[91,   600] loss: 0.392\n",
      "[91,   900] loss: 0.407\n",
      "[92,   300] loss: 0.391\n",
      "[92,   600] loss: 0.396\n",
      "[92,   900] loss: 0.400\n",
      "[93,   300] loss: 0.391\n",
      "[93,   600] loss: 0.390\n",
      "[93,   900] loss: 0.405\n",
      "[94,   300] loss: 0.382\n",
      "[94,   600] loss: 0.401\n",
      "[94,   900] loss: 0.395\n",
      "[95,   300] loss: 0.387\n",
      "[95,   600] loss: 0.390\n",
      "[95,   900] loss: 0.401\n",
      "[96,   300] loss: 0.391\n",
      "[96,   600] loss: 0.395\n",
      "[96,   900] loss: 0.392\n",
      "[97,   300] loss: 0.386\n",
      "[97,   600] loss: 0.393\n",
      "[97,   900] loss: 0.399\n",
      "[98,   300] loss: 0.384\n",
      "[98,   600] loss: 0.385\n",
      "[98,   900] loss: 0.416\n",
      "[99,   300] loss: 0.392\n",
      "[99,   600] loss: 0.392\n",
      "[99,   900] loss: 0.395\n",
      "[100,   300] loss: 0.384\n",
      "[100,   600] loss: 0.388\n",
      "[100,   900] loss: 0.404\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(100):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b98e7517",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-05T07:44:15.455152Z",
     "start_time": "2021-08-05T07:44:08.865742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 5, 6,  ..., 6, 6, 6])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Categorical categories must be unique",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-19f383678a74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_predict.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mpredict_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-19f383678a74>\u001b[0m in \u001b[0;36mpredict_save\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mlables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Class_1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Class_2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Class_3'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Class_4'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Class_5'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Class_6'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Class_7'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Class_8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Class_9'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlables\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    952\u001b[0m             \u001b[0msparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m             \u001b[0mdrop_first\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_first\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m         )\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py\u001b[0m in \u001b[0;36m_get_dummies_1d\u001b[1;34m(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    969\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m     \u001b[1;31m# Series avoids inconsistent NaN handling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m     \u001b[0mcodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfactorize_from_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001b[0m in \u001b[0;36mfactorize_from_iterable\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   2752\u001b[0m         \u001b[1;31m# but only the resulting categories, the order of which is independent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2753\u001b[0m         \u001b[1;31m# from ordered. Set ordered to False as default. See GH #15457\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2754\u001b[1;33m         \u001b[0mcat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2755\u001b[0m         \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2756\u001b[0m         \u001b[0mcodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\arrays\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, values, categories, ordered, dtype, fastpath, copy)\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;31m# we're inferring from values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m             \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mordered\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, categories, ordered)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOrdered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_finalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\u001b[0m in \u001b[0;36m_finalize\u001b[1;34m(self, categories, ordered, fastpath)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcategories\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 337\u001b[1;33m             \u001b[0mcategories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_categories\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfastpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_categories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\pandas\\core\\dtypes\\dtypes.py\u001b[0m in \u001b[0;36mvalidate_categories\u001b[1;34m(categories, fastpath)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcategories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Categorical categories must be unique\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    541\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCCategoricalIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Categorical categories must be unique"
     ]
    }
   ],
   "source": [
    "def predict_save():\n",
    "    data_test = pd.read_csv(\"data/otto/test.csv\")\n",
    "    test_inputs = torch.Tensor(np.array(data_test)[:,1:])\n",
    "    outputs = model.predict(test_inputs.float())\n",
    "    print(outputs)\n",
    "    outputs = pd.get_dummies(outputs)\n",
    "    lables=['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']\n",
    "    outputs.columns = lables\n",
    "    outputs.insert(0,'id',data_test['id'])\n",
    "    outputs = pd.DataFrame(outputs)\n",
    "    outputs.to_csvs('my_predict.csv', index=False)\n",
    "    \n",
    "predict_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba963ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
