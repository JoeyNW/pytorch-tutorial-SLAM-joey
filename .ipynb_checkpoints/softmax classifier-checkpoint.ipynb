{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb157aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T03:41:15.947124Z",
     "start_time": "2021-08-04T03:40:10.739149Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: data/mnist/MNIST\\raw\\train-images-idx3-ubyte.gz\n",
      "Extracting data/mnist/MNIST\\raw\\train-images-idx3-ubyte.gz to data/mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "113.5%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/MNIST\\raw\\train-labels-idx1-ubyte.gz to data/mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.4%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/MNIST\\raw\\t10k-images-idx3-ubyte.gz to data/mnist/MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180.4%D:\\Anaconda\\envs\\pytorch_gpu\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/mnist/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data/mnist/MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# class\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "# prepare data\n",
    "batch_size = 64\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))]) # 转换为网络需要的格式以及标准化，均值，方差\n",
    "\n",
    "train_dataset = datasets.MNIST(root='data/mnist/', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "test_dataset = datasets.MNIST(root='data/mnist/', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6692ce1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T03:44:27.977111Z",
     "start_time": "2021-08-04T03:44:26.330538Z"
    }
   },
   "outputs": [],
   "source": [
    "# design model using class\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(784, 512)\n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 128)\n",
    "        self.l4 = torch.nn.Linear(128, 64)\n",
    "        self.l5 = torch.nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # -1表示自动计算784的个数，也就是有多少个样本\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        x = F.relu(self.l4(x))\n",
    "        return self.l5(x) # 最后一层不做激活，因为要用crossentropy，自带了softmax\n",
    "    \n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "991815ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:12:08.865328Z",
     "start_time": "2021-08-04T07:12:08.854385Z"
    }
   },
   "outputs": [],
   "source": [
    "# construct loss and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01, momentum=0.5)\n",
    "\n",
    "# train cycle\n",
    "def train(epoch):\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, data in enumerate(train_loader, 0):\n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()\n",
    "        # 获得预测结果\n",
    "        outputs = model(inputs)\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if batch_idx % 300 == 299:\n",
    "            print(\"[%d, %5d] loss: %.3f\" % (epoch+1, batch_idx+1, running_loss/300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _,predicted = torch.max(outputs.data, dim=1) #dim=1，从列的方向找寻最大值，返回的第一个参数是值，第二个值是下标\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"accracy on test_set: %d %%\" % (100*correct/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8795dee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:15:14.895851Z",
     "start_time": "2021-08-04T07:12:44.356671Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 2.248\n",
      "[1,   600] loss: 1.043\n",
      "[1,   900] loss: 0.457\n",
      "accracy on test_set: 87 %\n",
      "[2,   300] loss: 0.327\n",
      "[2,   600] loss: 0.272\n",
      "[2,   900] loss: 0.243\n",
      "accracy on test_set: 94 %\n",
      "[3,   300] loss: 0.190\n",
      "[3,   600] loss: 0.173\n",
      "[3,   900] loss: 0.151\n",
      "accracy on test_set: 95 %\n",
      "[4,   300] loss: 0.132\n",
      "[4,   600] loss: 0.117\n",
      "[4,   900] loss: 0.121\n",
      "accracy on test_set: 96 %\n",
      "[5,   300] loss: 0.099\n",
      "[5,   600] loss: 0.097\n",
      "[5,   900] loss: 0.089\n",
      "accracy on test_set: 96 %\n",
      "[6,   300] loss: 0.074\n",
      "[6,   600] loss: 0.080\n",
      "[6,   900] loss: 0.073\n",
      "accracy on test_set: 97 %\n",
      "[7,   300] loss: 0.063\n",
      "[7,   600] loss: 0.061\n",
      "[7,   900] loss: 0.061\n",
      "accracy on test_set: 97 %\n",
      "[8,   300] loss: 0.049\n",
      "[8,   600] loss: 0.047\n",
      "[8,   900] loss: 0.055\n",
      "accracy on test_set: 97 %\n",
      "[9,   300] loss: 0.038\n",
      "[9,   600] loss: 0.044\n",
      "[9,   900] loss: 0.044\n",
      "accracy on test_set: 97 %\n",
      "[10,   300] loss: 0.031\n",
      "[10,   600] loss: 0.035\n",
      "[10,   900] loss: 0.034\n",
      "accracy on test_set: 97 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52170625",
   "metadata": {},
   "source": [
    "# practice-otto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd2ad17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-04T07:58:32.667529Z",
     "start_time": "2021-08-04T07:58:27.412890Z"
    }
   },
   "outputs": [],
   "source": [
    "# otto\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data_train = pd.read_csv(\"data/otto/train.csv\")\n",
    "# data_test = pd.read_csv(\"data/otto/test.csv\")\n",
    "\n",
    "# 将类别标签转换为数字\n",
    "def label2id(lables):\n",
    "    target_id = []\n",
    "    target_labels = ['Class_1', 'Class_2', 'Class_3', 'Class_4', 'Class_5', 'Class_6', 'Class_7', 'Class_8', 'Class_9']\n",
    "    for label in lables:\n",
    "        target_id.append(target_labels.index(label))\n",
    "    return target_id\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# prepare dataset\n",
    "class OttoDataset(Dataset):\n",
    "    def __init__(self, filepath):\n",
    "        data = pd.read_csv(filepath)\n",
    "        lables = data['target']\n",
    "        self.len = data.shape[0]\n",
    "        \n",
    "        self.x_data = torch.from_numpy(np.array(data)[:,1:-1])\n",
    "        self.y_data = label2id(lables)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "data_train = OttoDataset(\"data/otto/train.csv\")\n",
    "# data_test = OttoDataset(\"data/otto/test.csv\")\n",
    "train_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37213fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design model using class\n",
    "\n",
    "class ottoNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(93, 64)\n",
    "        self.l2 = torch.nn.Linear(64, 32)\n",
    "        self.l3 = torch.nn.Linear(32, 16)\n",
    "        self.l4 = torch.nn.Linear(16, 9)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.l1(x))\n",
    "        x = F.relu(self.l2(x))\n",
    "        x = F.relu(self.l3(x))\n",
    "        return self.l4(x) # 最后一层不做激活，因为要用crossentropy，自带了softmax\n",
    "    \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            x = F.relu(self.l1(x))\n",
    "            x = F.relu(self.l2(x))\n",
    "            x = F.relu(self.l3(x))\n",
    "            x = F.relu(self.l4(x))\n",
    "model = ottoNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f20b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contruct loss and optimzer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "def train(epoch):\n",
    "    running_loss=0.0\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        inputs, target = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if batch_idx % 300 == 299:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, batch_idx+1, running_loss/300))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
